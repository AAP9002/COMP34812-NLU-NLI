{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UnOgaPA41fkr"
   },
   "source": [
    "# COMP34812 Natural Language Understanding Courseworklow key lemming an stemming\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmSUwder1fkt"
   },
   "source": [
    "## Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FqR9evYQ1fku",
    "outputId": "f35fd907-8027-4e57-c0c3-42bca35f21fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\zaccu\\onedrive\\documents\\github\\comp34812-nlu-nli\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\zaccu\\onedrive\\documents\\github\\comp34812-nlu-nli\\.venv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\zaccu\\onedrive\\documents\\github\\comp34812-nlu-nli\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\zaccu\\onedrive\\documents\\github\\comp34812-nlu-nli\\.venv\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\zaccu\\onedrive\\documents\\github\\comp34812-nlu-nli\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\zaccu\\onedrive\\documents\\github\\comp34812-nlu-nli\\.venv\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\zaccu\\onedrive\\documents\\github\\comp34812-nlu-nli\\.venv\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\zaccu\\onedrive\\documents\\github\\comp34812-nlu-nli\\.venv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\zaccu\\onedrive\\documents\\github\\comp34812-nlu-nli\\.venv\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: click in c:\\users\\zaccu\\onedrive\\documents\\github\\comp34812-nlu-nli\\.venv\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\zaccu\\onedrive\\documents\\github\\comp34812-nlu-nli\\.venv\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\zaccu\\onedrive\\documents\\github\\comp34812-nlu-nli\\.venv\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\zaccu\\onedrive\\documents\\github\\comp34812-nlu-nli\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\zaccu\\onedrive\\documents\\github\\comp34812-nlu-nli\\.venv\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\zaccu\\onedrive\\documents\\github\\comp34812-nlu-nli\\.venv\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\zaccu\\onedrive\\documents\\github\\comp34812-nlu-nli\\.venv\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\zaccu\\onedrive\\documents\\github\\comp34812-nlu-nli\\.venv\\lib\\site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\zaccu\\onedrive\\documents\\github\\comp34812-nlu-nli\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zaccu\\onedrive\\documents\\github\\comp34812-nlu-nli\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\zaccu\\onedrive\\documents\\github\\comp34812-nlu-nli\\.venv\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas nltk numpy matplotlib scikit-learn sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UChWsR7O1fku",
    "outputId": "588c9b21-3c6e-41cc-a728-3ea9245dd8de"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\zaccu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zaccu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "import numpy as np\n",
    "import nltk\n",
    "import os\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H5Qier3D1iSF",
    "outputId": "0e3e8db0-cd00-4949-9af5-d7a54822fecf"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('glove_embeddings'):\n",
    "  !wget https://nlp.stanford.edu/data/glove.6B.zip\n",
    "  !unzip glove.6B.zip -d glove_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_DqwdkY1fkv"
   },
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MhHy7Sby1fkw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>By starting at the soft underbelly, the 16,000...</td>\n",
       "      <td>General Nelson A. Miles had 30,000 troops in h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The class had broken into a light sweat, but w...</td>\n",
       "      <td>The class grew more tense as time went on.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Samson had his famous haircut here, but he wou...</td>\n",
       "      <td>It was unknown where exactly within the town S...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A man with a black shirt holds a baby while a ...</td>\n",
       "      <td>A darkly dressed man passes a crying baby to a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I know that many of you are interested in addr...</td>\n",
       "      <td>The problems must be addressed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  By starting at the soft underbelly, the 16,000...   \n",
       "1  The class had broken into a light sweat, but w...   \n",
       "2  Samson had his famous haircut here, but he wou...   \n",
       "3  A man with a black shirt holds a baby while a ...   \n",
       "4  I know that many of you are interested in addr...   \n",
       "\n",
       "                                          hypothesis  label  \n",
       "0  General Nelson A. Miles had 30,000 troops in h...      0  \n",
       "1         The class grew more tense as time went on.      1  \n",
       "2  It was unknown where exactly within the town S...      1  \n",
       "3  A darkly dressed man passes a crying baby to a...      0  \n",
       "4                    The problems must be addressed       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_set = pd.read_csv('dev.csv')\n",
    "dev_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PQlmvS1I1fkw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yeah i don't know cut California in half or so...</td>\n",
       "      <td>Yeah. I'm not sure how to make that fit. Maybe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actual names will not be used</td>\n",
       "      <td>For the sake of privacy, actual names are not ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The film was directed by Randall Wallace.</td>\n",
       "      <td>The film was directed by Randall Wallace and s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"How d'you know he'll sign me on?\"Anse studie...</td>\n",
       "      <td>Anse looked at himself in a cracked mirror.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the light of the candles his cheeks looked ...</td>\n",
       "      <td>Drew regarded his best friend and noted that i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  yeah i don't know cut California in half or so...   \n",
       "1                      actual names will not be used   \n",
       "2          The film was directed by Randall Wallace.   \n",
       "3   \"How d'you know he'll sign me on?\"Anse studie...   \n",
       "4  In the light of the candles his cheeks looked ...   \n",
       "\n",
       "                                          hypothesis  label  \n",
       "0  Yeah. I'm not sure how to make that fit. Maybe...      1  \n",
       "1  For the sake of privacy, actual names are not ...      1  \n",
       "2  The film was directed by Randall Wallace and s...      1  \n",
       "3       Anse looked at himself in a cracked mirror.       1  \n",
       "4  Drew regarded his best friend and noted that i...      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = pd.read_csv('train.csv')\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ExYfX91t1fkx"
   },
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "\n",
    "    text = nltk.word_tokenize(text)\n",
    "\n",
    "    processed = []\n",
    "    for word in text:\n",
    "        if word in stop_words:\n",
    "            continue\n",
    "\n",
    "        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "        word = word.strip()\n",
    "\n",
    "        if len(word) < 2:\n",
    "            continue\n",
    "\n",
    "        processed.append(word)\n",
    "\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "UqAFgu8l1fky"
   },
   "outputs": [],
   "source": [
    "dev_set['premise_tokens'] = dev_set['premise'].apply(clean_text)\n",
    "dev_set['hypothesis_tokens'] = dev_set['hypothesis'].apply(clean_text)\n",
    "\n",
    "train_set['premise_tokens'] = train_set['premise'].apply(clean_text)\n",
    "train_set['hypothesis_tokens'] = train_set['hypothesis'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "BRmvOcx11fkz"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "      <th>premise_tokens</th>\n",
       "      <th>hypothesis_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>By starting at the soft underbelly, the 16,000...</td>\n",
       "      <td>General Nelson A. Miles had 30,000 troops in h...</td>\n",
       "      <td>0</td>\n",
       "      <td>[starting, soft, underbelly, 16, 000, troop, g...</td>\n",
       "      <td>[general, nelson, mile, 30, 000, troop, attack]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The class had broken into a light sweat, but w...</td>\n",
       "      <td>The class grew more tense as time went on.</td>\n",
       "      <td>1</td>\n",
       "      <td>[class, broken, light, sweat, gasping, air]</td>\n",
       "      <td>[class, grew, tense, time, went]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Samson had his famous haircut here, but he wou...</td>\n",
       "      <td>It was unknown where exactly within the town S...</td>\n",
       "      <td>1</td>\n",
       "      <td>[samson, famous, haircut, would, find, hard, r...</td>\n",
       "      <td>[unknown, exactly, within, town, samson, recei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A man with a black shirt holds a baby while a ...</td>\n",
       "      <td>A darkly dressed man passes a crying baby to a...</td>\n",
       "      <td>0</td>\n",
       "      <td>[man, black, shirt, hold, baby, blue, shirted,...</td>\n",
       "      <td>[darkly, dressed, man, pass, cry, baby, man, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I know that many of you are interested in addr...</td>\n",
       "      <td>The problems must be addressed</td>\n",
       "      <td>1</td>\n",
       "      <td>[know, many, interested, addressing, issue, le...</td>\n",
       "      <td>[problem, must, addressed]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  By starting at the soft underbelly, the 16,000...   \n",
       "1  The class had broken into a light sweat, but w...   \n",
       "2  Samson had his famous haircut here, but he wou...   \n",
       "3  A man with a black shirt holds a baby while a ...   \n",
       "4  I know that many of you are interested in addr...   \n",
       "\n",
       "                                          hypothesis  label  \\\n",
       "0  General Nelson A. Miles had 30,000 troops in h...      0   \n",
       "1         The class grew more tense as time went on.      1   \n",
       "2  It was unknown where exactly within the town S...      1   \n",
       "3  A darkly dressed man passes a crying baby to a...      0   \n",
       "4                    The problems must be addressed       1   \n",
       "\n",
       "                                      premise_tokens  \\\n",
       "0  [starting, soft, underbelly, 16, 000, troop, g...   \n",
       "1        [class, broken, light, sweat, gasping, air]   \n",
       "2  [samson, famous, haircut, would, find, hard, r...   \n",
       "3  [man, black, shirt, hold, baby, blue, shirted,...   \n",
       "4  [know, many, interested, addressing, issue, le...   \n",
       "\n",
       "                                   hypothesis_tokens  \n",
       "0    [general, nelson, mile, 30, 000, troop, attack]  \n",
       "1                   [class, grew, tense, time, went]  \n",
       "2  [unknown, exactly, within, town, samson, recei...  \n",
       "3  [darkly, dressed, man, pass, cry, baby, man, l...  \n",
       "4                         [problem, must, addressed]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yd8StseU1fkz"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "      <th>premise_tokens</th>\n",
       "      <th>hypothesis_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yeah i don't know cut California in half or so...</td>\n",
       "      <td>Yeah. I'm not sure how to make that fit. Maybe...</td>\n",
       "      <td>1</td>\n",
       "      <td>[yeah, know, cut, california, half, something]</td>\n",
       "      <td>[yeah, sure, make, fit, maybe, could, cut, cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actual names will not be used</td>\n",
       "      <td>For the sake of privacy, actual names are not ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[actual, name, used]</td>\n",
       "      <td>[sake, privacy, actual, name, used]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The film was directed by Randall Wallace.</td>\n",
       "      <td>The film was directed by Randall Wallace and s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[film, directed, randall, wallace]</td>\n",
       "      <td>[film, directed, randall, wallace, star, mel, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"How d'you know he'll sign me on?\"Anse studie...</td>\n",
       "      <td>Anse looked at himself in a cracked mirror.</td>\n",
       "      <td>1</td>\n",
       "      <td>[know, sign, anse, studied, unkempt, clean, re...</td>\n",
       "      <td>[anse, looked, cracked, mirror]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the light of the candles his cheeks looked ...</td>\n",
       "      <td>Drew regarded his best friend and noted that i...</td>\n",
       "      <td>1</td>\n",
       "      <td>[light, candle, cheek, looked, even, hollow, t...</td>\n",
       "      <td>[drew, regarded, best, friend, noted, light, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  yeah i don't know cut California in half or so...   \n",
       "1                      actual names will not be used   \n",
       "2          The film was directed by Randall Wallace.   \n",
       "3   \"How d'you know he'll sign me on?\"Anse studie...   \n",
       "4  In the light of the candles his cheeks looked ...   \n",
       "\n",
       "                                          hypothesis  label  \\\n",
       "0  Yeah. I'm not sure how to make that fit. Maybe...      1   \n",
       "1  For the sake of privacy, actual names are not ...      1   \n",
       "2  The film was directed by Randall Wallace and s...      1   \n",
       "3       Anse looked at himself in a cracked mirror.       1   \n",
       "4  Drew regarded his best friend and noted that i...      1   \n",
       "\n",
       "                                      premise_tokens  \\\n",
       "0     [yeah, know, cut, california, half, something]   \n",
       "1                               [actual, name, used]   \n",
       "2                 [film, directed, randall, wallace]   \n",
       "3  [know, sign, anse, studied, unkempt, clean, re...   \n",
       "4  [light, candle, cheek, looked, even, hollow, t...   \n",
       "\n",
       "                                   hypothesis_tokens  \n",
       "0  [yeah, sure, make, fit, maybe, could, cut, cal...  \n",
       "1                [sake, privacy, actual, name, used]  \n",
       "2  [film, directed, randall, wallace, star, mel, ...  \n",
       "3                    [anse, looked, cracked, mirror]  \n",
       "4  [drew, regarded, best, friend, noted, light, l...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9JrXj2d1fk1"
   },
   "source": [
    "Dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "YmG2nSeG1fk1"
   },
   "outputs": [],
   "source": [
    "# Labels = dev_set['label'].unique()\n",
    "# Labels\n",
    "\n",
    "# def get_word_frequency(data):\n",
    "#     word_freq = {}\n",
    "#     for row in data:\n",
    "#         for word in row:\n",
    "#             if word in word_freq:\n",
    "#                 word_freq[word] += 1\n",
    "#             else:\n",
    "#                 word_freq[word] = 1\n",
    "#     return word_freq\n",
    "\n",
    "# word_freq = get_word_frequency(train_set['premise_tokens'] + train_set['hypothesis'])\n",
    "\n",
    "# # nltk FreqDist\n",
    "# from nltk import FreqDist\n",
    "\n",
    "# fdist = FreqDist(word_freq)\n",
    "# fdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BPE tokinizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "# Train BPE on training dataset (premises + hypotheses combined)\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input= concat(train_set['premise'],train_set['hypothosis']) ,  # A file where each line is a sentence from the dataset\n",
    "    model_prefix=\"bpe\", \n",
    "    vocab_size=10000,  # Adjust as needed\n",
    "    model_type=\"bpe\"\n",
    ")\n",
    "\n",
    "# Load trained BPE tokenizer\n",
    "#bpe = spm.SentencePieceProcessor(model_file=\"bpe.model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPJR8Bl-1fk1"
   },
   "source": [
    "# Glove embeddings and tfif wieghted word emeddings plus named eneitiy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cTLuOgi81fk1"
   },
   "outputs": [],
   "source": [
    "glove = \"./glove_embeddings/glove.6B.200d.txt\"\n",
    "def load_glove(glove_file):\n",
    "    embeddings_dict = {}\n",
    "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.strip().split()\n",
    "            word = values[0]\n",
    "            vector = np.array(values[1:], dtype=np.float32)  # <-- Convert to float32\n",
    "            embeddings_dict[word] = vector\n",
    "    return embeddings_dict\n",
    "\n",
    "embedding_dim = 200\n",
    "loaded_glove = load_glove(glove)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_l1pjn5z1fk1"
   },
   "outputs": [],
   "source": [
    "def sentence_embedding(tokens, embeddings_dict, embedding_dim):\n",
    "    valid_embeddings = [embeddings_dict[token] for token in tokens if token in embeddings_dict]\n",
    "    if not valid_embeddings:\n",
    "        # Return zero-vector if no embeddings found\n",
    "        return np.zeros(embedding_dim)\n",
    "    sentence_emb = np.mean(valid_embeddings, axis=0)\n",
    "    return sentence_emb\n",
    "\n",
    "def pairwise_embedding(premise_tokens, hypothesis_tokens, embeddings_dict,embedding_dim):\n",
    "    premise_emb = sentence_embedding(premise_tokens, embeddings_dict,embedding_dim)\n",
    "    hypothesis_emb = sentence_embedding(hypothesis_tokens, embeddings_dict,embedding_dim)\n",
    "    # Concatenate multiple useful features\n",
    "    combined_emb = np.concatenate([\n",
    "        premise_emb,\n",
    "        hypothesis_emb,\n",
    "        np.abs(premise_emb - hypothesis_emb), # capture difference\n",
    "        premise_emb * hypothesis_emb           # capture interactions\n",
    "    ]).astype(np.float32)\n",
    "\n",
    "    return combined_emb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "K9GWj68p1fk2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24432/24432 [00:01<00:00, 15440.59it/s]\n",
      "100%|██████████| 6736/6736 [00:00<00:00, 15633.66it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Convert list of numpy arrays into a single 2D numpy array\n",
    "train_embeddings = np.stack(train_set.progress_apply(\n",
    "    lambda x: pairwise_embedding(x['premise_tokens'], x['hypothesis_tokens'], loaded_glove, embedding_dim=200), axis=1))\n",
    "\n",
    "dev_embeddings = np.stack(dev_set.progress_apply(\n",
    "    lambda x: pairwise_embedding(x['premise_tokens'], x['hypothesis_tokens'], loaded_glove, embedding_dim=200), axis=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0alJR9Dd1fk2"
   },
   "source": [
    "# Traditional Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "puV0EXHm1fk2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 30 candidates, totalling 60 fits\n",
      "Best Parameters: {'C': 0.1, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   entailment       0.59      0.51      0.55      3258\n",
      "contradiction       0.59      0.66      0.62      3478\n",
      "\n",
      "     accuracy                           0.59      6736\n",
      "    macro avg       0.59      0.59      0.58      6736\n",
      " weighted avg       0.59      0.59      0.59      6736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'solver': ['lbfgs', 'liblinear'],  # Different solvers for logistic regression\n",
    "    'max_iter': [500, 1000, 2000]  # More iterations for convergence\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(LogisticRegression(), param_grid, cv=3, scoring='f1_macro', verbose=1, n_jobs=-1)\n",
    "clf.fit(train_embeddings, train_set[\"label\"].values)  # Train on enhanced embeddings\n",
    "\n",
    "# Print Best Parameters\n",
    "print(\"Best Parameters:\", clf.best_params_)\n",
    "\n",
    "# Evaluate on validation set\n",
    "preds = clf.best_estimator_.predict(dev_embeddings)\n",
    "print(classification_report(dev_set['label'].values, preds, target_names=['entailment', 'contradiction']))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
