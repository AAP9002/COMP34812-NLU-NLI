{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP34812 Natural Language Understanding Courseworklow key lemming an stemming\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install required packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas nltk numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\zaccu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zaccu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>By starting at the soft underbelly, the 16,000...</td>\n",
       "      <td>General Nelson A. Miles had 30,000 troops in h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The class had broken into a light sweat, but w...</td>\n",
       "      <td>The class grew more tense as time went on.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Samson had his famous haircut here, but he wou...</td>\n",
       "      <td>It was unknown where exactly within the town S...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A man with a black shirt holds a baby while a ...</td>\n",
       "      <td>A darkly dressed man passes a crying baby to a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I know that many of you are interested in addr...</td>\n",
       "      <td>The problems must be addressed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  By starting at the soft underbelly, the 16,000...   \n",
       "1  The class had broken into a light sweat, but w...   \n",
       "2  Samson had his famous haircut here, but he wou...   \n",
       "3  A man with a black shirt holds a baby while a ...   \n",
       "4  I know that many of you are interested in addr...   \n",
       "\n",
       "                                          hypothesis  label  \n",
       "0  General Nelson A. Miles had 30,000 troops in h...      0  \n",
       "1         The class grew more tense as time went on.      1  \n",
       "2  It was unknown where exactly within the town S...      1  \n",
       "3  A darkly dressed man passes a crying baby to a...      0  \n",
       "4                    The problems must be addressed       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_set = pd.read_csv('dev.csv')\n",
    "dev_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yeah i don't know cut California in half or so...</td>\n",
       "      <td>Yeah. I'm not sure how to make that fit. Maybe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actual names will not be used</td>\n",
       "      <td>For the sake of privacy, actual names are not ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The film was directed by Randall Wallace.</td>\n",
       "      <td>The film was directed by Randall Wallace and s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"How d'you know he'll sign me on?\"Anse studie...</td>\n",
       "      <td>Anse looked at himself in a cracked mirror.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the light of the candles his cheeks looked ...</td>\n",
       "      <td>Drew regarded his best friend and noted that i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  yeah i don't know cut California in half or so...   \n",
       "1                      actual names will not be used   \n",
       "2          The film was directed by Randall Wallace.   \n",
       "3   \"How d'you know he'll sign me on?\"Anse studie...   \n",
       "4  In the light of the candles his cheeks looked ...   \n",
       "\n",
       "                                          hypothesis  label  \n",
       "0  Yeah. I'm not sure how to make that fit. Maybe...      1  \n",
       "1  For the sake of privacy, actual names are not ...      1  \n",
       "2  The film was directed by Randall Wallace and s...      1  \n",
       "3       Anse looked at himself in a cracked mirror.       1  \n",
       "4  Drew regarded his best friend and noted that i...      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = pd.read_csv('train.csv')\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "\n",
    "    text = nltk.word_tokenize(text)\n",
    "\n",
    "    processed = []\n",
    "    for word in text:\n",
    "        if word in stop_words:\n",
    "            continue\n",
    "\n",
    "        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "        word = word.strip()\n",
    "\n",
    "        if len(word) < 2:\n",
    "            continue\n",
    "\n",
    "        processed.append(word)\n",
    "\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_set['premise_tokens'] = dev_set['premise'].apply(clean_text)\n",
    "dev_set['hypothesis_tokens'] = dev_set['hypothesis'].apply(clean_text)\n",
    "\n",
    "train_set['premise_tokens'] = train_set['premise'].apply(clean_text)\n",
    "train_set['hypothesis_tokens'] = train_set['hypothesis'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "      <th>premise_tokens</th>\n",
       "      <th>hypothesis_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>By starting at the soft underbelly, the 16,000...</td>\n",
       "      <td>General Nelson A. Miles had 30,000 troops in h...</td>\n",
       "      <td>0</td>\n",
       "      <td>[starting, soft, underbelly, 16, 000, troop, g...</td>\n",
       "      <td>[general, nelson, mile, 30, 000, troop, attack]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The class had broken into a light sweat, but w...</td>\n",
       "      <td>The class grew more tense as time went on.</td>\n",
       "      <td>1</td>\n",
       "      <td>[class, broken, light, sweat, gasping, air]</td>\n",
       "      <td>[class, grew, tense, time, went]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Samson had his famous haircut here, but he wou...</td>\n",
       "      <td>It was unknown where exactly within the town S...</td>\n",
       "      <td>1</td>\n",
       "      <td>[samson, famous, haircut, would, find, hard, r...</td>\n",
       "      <td>[unknown, exactly, within, town, samson, recei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A man with a black shirt holds a baby while a ...</td>\n",
       "      <td>A darkly dressed man passes a crying baby to a...</td>\n",
       "      <td>0</td>\n",
       "      <td>[man, black, shirt, hold, baby, blue, shirted,...</td>\n",
       "      <td>[darkly, dressed, man, pass, cry, baby, man, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I know that many of you are interested in addr...</td>\n",
       "      <td>The problems must be addressed</td>\n",
       "      <td>1</td>\n",
       "      <td>[know, many, interested, addressing, issue, le...</td>\n",
       "      <td>[problem, must, addressed]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  By starting at the soft underbelly, the 16,000...   \n",
       "1  The class had broken into a light sweat, but w...   \n",
       "2  Samson had his famous haircut here, but he wou...   \n",
       "3  A man with a black shirt holds a baby while a ...   \n",
       "4  I know that many of you are interested in addr...   \n",
       "\n",
       "                                          hypothesis  label  \\\n",
       "0  General Nelson A. Miles had 30,000 troops in h...      0   \n",
       "1         The class grew more tense as time went on.      1   \n",
       "2  It was unknown where exactly within the town S...      1   \n",
       "3  A darkly dressed man passes a crying baby to a...      0   \n",
       "4                    The problems must be addressed       1   \n",
       "\n",
       "                                      premise_tokens  \\\n",
       "0  [starting, soft, underbelly, 16, 000, troop, g...   \n",
       "1        [class, broken, light, sweat, gasping, air]   \n",
       "2  [samson, famous, haircut, would, find, hard, r...   \n",
       "3  [man, black, shirt, hold, baby, blue, shirted,...   \n",
       "4  [know, many, interested, addressing, issue, le...   \n",
       "\n",
       "                                   hypothesis_tokens  \n",
       "0    [general, nelson, mile, 30, 000, troop, attack]  \n",
       "1                   [class, grew, tense, time, went]  \n",
       "2  [unknown, exactly, within, town, samson, recei...  \n",
       "3  [darkly, dressed, man, pass, cry, baby, man, l...  \n",
       "4                         [problem, must, addressed]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "      <th>premise_tokens</th>\n",
       "      <th>hypothesis_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yeah i don't know cut California in half or so...</td>\n",
       "      <td>Yeah. I'm not sure how to make that fit. Maybe...</td>\n",
       "      <td>1</td>\n",
       "      <td>[yeah, know, cut, california, half, something]</td>\n",
       "      <td>[yeah, sure, make, fit, maybe, could, cut, cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actual names will not be used</td>\n",
       "      <td>For the sake of privacy, actual names are not ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[actual, name, used]</td>\n",
       "      <td>[sake, privacy, actual, name, used]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The film was directed by Randall Wallace.</td>\n",
       "      <td>The film was directed by Randall Wallace and s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[film, directed, randall, wallace]</td>\n",
       "      <td>[film, directed, randall, wallace, star, mel, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"How d'you know he'll sign me on?\"Anse studie...</td>\n",
       "      <td>Anse looked at himself in a cracked mirror.</td>\n",
       "      <td>1</td>\n",
       "      <td>[know, sign, anse, studied, unkempt, clean, re...</td>\n",
       "      <td>[anse, looked, cracked, mirror]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the light of the candles his cheeks looked ...</td>\n",
       "      <td>Drew regarded his best friend and noted that i...</td>\n",
       "      <td>1</td>\n",
       "      <td>[light, candle, cheek, looked, even, hollow, t...</td>\n",
       "      <td>[drew, regarded, best, friend, noted, light, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  yeah i don't know cut California in half or so...   \n",
       "1                      actual names will not be used   \n",
       "2          The film was directed by Randall Wallace.   \n",
       "3   \"How d'you know he'll sign me on?\"Anse studie...   \n",
       "4  In the light of the candles his cheeks looked ...   \n",
       "\n",
       "                                          hypothesis  label  \\\n",
       "0  Yeah. I'm not sure how to make that fit. Maybe...      1   \n",
       "1  For the sake of privacy, actual names are not ...      1   \n",
       "2  The film was directed by Randall Wallace and s...      1   \n",
       "3       Anse looked at himself in a cracked mirror.       1   \n",
       "4  Drew regarded his best friend and noted that i...      1   \n",
       "\n",
       "                                      premise_tokens  \\\n",
       "0     [yeah, know, cut, california, half, something]   \n",
       "1                               [actual, name, used]   \n",
       "2                 [film, directed, randall, wallace]   \n",
       "3  [know, sign, anse, studied, unkempt, clean, re...   \n",
       "4  [light, candle, cheek, looked, even, hollow, t...   \n",
       "\n",
       "                                   hypothesis_tokens  \n",
       "0  [yeah, sure, make, fit, maybe, could, cut, cal...  \n",
       "1                [sake, privacy, actual, name, used]  \n",
       "2  [film, directed, randall, wallace, star, mel, ...  \n",
       "3                    [anse, looked, cracked, mirror]  \n",
       "4  [drew, regarded, best, friend, noted, light, l...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels = dev_set['label'].unique()\n",
    "# Labels\n",
    "\n",
    "# def get_word_frequency(data):\n",
    "#     word_freq = {}\n",
    "#     for row in data:\n",
    "#         for word in row:\n",
    "#             if word in word_freq:\n",
    "#                 word_freq[word] += 1\n",
    "#             else:\n",
    "#                 word_freq[word] = 1\n",
    "#     return word_freq\n",
    "\n",
    "# word_freq = get_word_frequency(train_set['premise_tokens'] + train_set['hypothesis'])\n",
    "\n",
    "# # nltk FreqDist\n",
    "# from nltk import FreqDist\n",
    "\n",
    "# fdist = FreqDist(word_freq)\n",
    "# fdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embeddings/ vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = \"./glove_embeddings/glove.6B.300d.txt\"\n",
    "def load_glove(glove_file):\n",
    "    with open(glove_file, 'r') as f:\n",
    "        word_to_vec = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            word = line[0]\n",
    "            vec = line[1:]\n",
    "            word_to_vec[word] = vec\n",
    "    return word_to_vec\n",
    "loaded_glove = load_glove(glove)\n",
    "embedding_dim = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_embedding(tokens, embeddings_dict, embedding_dim=300):\n",
    "    valid_embeddings = [embeddings_dict[token] for token in tokens if token in embeddings_dict]\n",
    "    \n",
    "    if not valid_embeddings:\n",
    "        # Return zero-vector if no embeddings found\n",
    "        return np.zeros(embedding_dim)\n",
    "    \n",
    "    sentence_emb = np.mean(valid_embeddings, axis=0)\n",
    "    return sentence_emb\n",
    "\n",
    "def pairwise_embedding(premise_tokens, hypothesis_tokens, embeddings_dict):\n",
    "    premise_emb = sentence_embedding(premise_tokens, embeddings_dict)\n",
    "    hypothesis_emb = sentence_embedding(hypothesis_tokens, embeddings_dict)\n",
    "    \n",
    "    # Concatenate multiple useful features\n",
    "    combined_emb = np.concatenate([\n",
    "        premise_emb,\n",
    "        hypothesis_emb,\n",
    "        np.abs(premise_emb - hypothesis_emb), # capture difference\n",
    "        premise_emb * hypothesis_emb           # capture interactions\n",
    "    ])\n",
    "    \n",
    "    return combined_emb \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/24432 [00:00<34:21, 11.85it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "the resolved dtypes are not compatible with add.reduce. Resolved (dtype('<U11'), dtype('<U11'), dtype('<U22'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m tqdm\u001b[38;5;241m.\u001b[39mpandas()  \u001b[38;5;66;03m# Enables `.progress_apply`\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Assuming glove_dict is already loaded\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m train_set[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_embedding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairwise_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpremise\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhypothesis\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaded_glove\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m dev_set[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_embedding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dev_set\u001b[38;5;241m.\u001b[39mprogress_apply(\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: pairwise_embedding(x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpremise\u001b[39m\u001b[38;5;124m'\u001b[39m], x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhypothesis\u001b[39m\u001b[38;5;124m'\u001b[39m], loaded_glove), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\zaccu\\OneDrive\\Documents\\GitHub\\COMP34812-NLU-NLI\\.venv\\lib\\site-packages\\tqdm\\std.py:917\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[1;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[0;32m    915\u001b[0m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(df, df_function)(wrapper, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m     t\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\zaccu\\OneDrive\\Documents\\GitHub\\COMP34812-NLU-NLI\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10373\u001b[0m )\n\u001b[1;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\zaccu\\OneDrive\\Documents\\GitHub\\COMP34812-NLU-NLI\\.venv\\lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zaccu\\OneDrive\\Documents\\GitHub\\COMP34812-NLU-NLI\\.venv\\lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32mc:\\Users\\zaccu\\OneDrive\\Documents\\GitHub\\COMP34812-NLU-NLI\\.venv\\lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\zaccu\\OneDrive\\Documents\\GitHub\\COMP34812-NLU-NLI\\.venv\\lib\\site-packages\\tqdm\\std.py:912\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[0;32m    908\u001b[0m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[0;32m    910\u001b[0m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[0;32m    911\u001b[0m     t\u001b[38;5;241m.\u001b[39mupdate(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m<\u001b[39m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[13], line 7\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      3\u001b[0m tqdm\u001b[38;5;241m.\u001b[39mpandas()  \u001b[38;5;66;03m# Enables `.progress_apply`\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Assuming glove_dict is already loaded\u001b[39;00m\n\u001b[0;32m      6\u001b[0m train_set[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_embedding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m train_set\u001b[38;5;241m.\u001b[39mprogress_apply(\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mpairwise_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpremise\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhypothesis\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaded_glove\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      9\u001b[0m dev_set[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_embedding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dev_set\u001b[38;5;241m.\u001b[39mprogress_apply(\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: pairwise_embedding(x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpremise\u001b[39m\u001b[38;5;124m'\u001b[39m], x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhypothesis\u001b[39m\u001b[38;5;124m'\u001b[39m], loaded_glove), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[12], line 12\u001b[0m, in \u001b[0;36mpairwise_embedding\u001b[1;34m(premise_tokens, hypothesis_tokens, embeddings_dict)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpairwise_embedding\u001b[39m(premise_tokens, hypothesis_tokens, embeddings_dict):\n\u001b[1;32m---> 12\u001b[0m     premise_emb \u001b[38;5;241m=\u001b[39m \u001b[43msentence_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpremise_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     hypothesis_emb \u001b[38;5;241m=\u001b[39m sentence_embedding(hypothesis_tokens, embeddings_dict)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Concatenate multiple useful features\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[12], line 8\u001b[0m, in \u001b[0;36msentence_embedding\u001b[1;34m(tokens, embeddings_dict, embedding_dim)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid_embeddings:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Return zero-vector if no embeddings found\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(embedding_dim)\n\u001b[1;32m----> 8\u001b[0m sentence_emb \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sentence_emb\n",
      "File \u001b[1;32mc:\\Users\\zaccu\\OneDrive\\Documents\\GitHub\\COMP34812-NLU-NLI\\.venv\\lib\\site-packages\\numpy\\_core\\fromnumeric.py:3860\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   3857\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3858\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 3860\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _methods\u001b[38;5;241m.\u001b[39m_mean(a, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   3861\u001b[0m                       out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\zaccu\\OneDrive\\Documents\\GitHub\\COMP34812-NLU-NLI\\.venv\\lib\\site-packages\\numpy\\_core\\_methods.py:135\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    132\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m mu\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    133\u001b[0m         is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 135\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    137\u001b[0m     ret \u001b[38;5;241m=\u001b[39m um\u001b[38;5;241m.\u001b[39mtrue_divide(\n\u001b[0;32m    138\u001b[0m             ret, rcount, out\u001b[38;5;241m=\u001b[39mret, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m'\u001b[39m, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: the resolved dtypes are not compatible with add.reduce. Resolved (dtype('<U11'), dtype('<U11'), dtype('<U22'))"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()  # Enables `.progress_apply`\n",
    "\n",
    "# Assuming glove_dict is already loaded\n",
    "train_set['combined_embedding'] = train_set.progress_apply(\n",
    "    lambda x: pairwise_embedding(x['premise_tokens'], x['hypothesis_tokens'], loaded_glove), axis=1)\n",
    "\n",
    "dev_set['combined_embedding'] = dev_set.progress_apply(\n",
    "    lambda x: pairwise_embedding(x['premise_tokens'], x['hypothesis_tokens'], loaded_glove), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(train_set['combined_embedding'], train_set['label'])\n",
    "\n",
    "# Evaluate on validation set\n",
    "preds = clf.predict(dev_set['combined_embedding'])\n",
    "print(classification_report(dev_set['label'], preds, target_names=['entailment', 'neutral', 'contradiction']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
